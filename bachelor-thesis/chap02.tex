\chapter{Hierarchical {P}lanning}

\medskip\noindent
Now that we have understood classical planning, we can move on to hierarchical planning or Hierarchical Task Network (HTN), to be precise. In HTN the goal alone is not to find an \emph{applicable plan} that will meet all of the criteria of the \emph{planning problem}. HTN focuses on accomplishing some set of tasks by decomposing them into sub-tasks with constraints like ordering and state conditions. A task is accomplished immediately upon all of his sub-tasks are accomplished. HTN is an extension of classical planning which gives us clues on how to find the proper \emph{plan}.

\medskip\noindent
As in classical planning, there are states of the world represented by the set of \emph{proposition symbols} or \emph{logical atoms} that are true in a state. We can \emph{apply actions} to states if the preconditions of \emph{actions} are satisfied (held in a state). These \emph{actions} will be called \emph{primitive tasks} in HTN. These tasks are executable right away and they change the current state to another one by applying negative and positive effects. In addition to \emph{primitive tasks} there are \emph{non-primitive tasks}. We will call them \emph{compound tasks}. These tasks cannot be executed and \emph{applied to a state}, rather they have to be decomposed into a set of sub-tasks using decomposition \emph{methods}, both \emph{primitive} and \emph{compound}. Having an \emph{initial task network}, that is a set of tasks and a set of constraints, the goal is to decompose all tasks into \emph{primitive tasks} and find an ordering of these tasks so that the constraints are not violated. After doing so, it is important to check that the resulting \emph{plan} (a sequence of \emph{primitive tasks}) is a valid \emph{plan} and can be \emph{applied} to an \emph{initial state}.

\medskip\noindent
All of the following definitions are correspondent and equivalent to the definitions in the book \emph{Automated Planning: theory and practice (Chapter 11)}~\cite{nau} and other publications~\cite{langclassification}~\cite{cmyk}~\cite{ondrckova2023semantics}~\cite{ondrckova2024empty}.

\section{HTN Planning}

\begin{defn}\label{def02:9}
    A \emph{task network} is a pair $\omega = (U,C)$, where $U$ is a set of \emph{tasks} (primitive and compound) and $C$ is a set of constraints.
    
    For a \emph{solution} (\emph{plan}) to be valid we need to satisfy all of the constraints listed in $C$. We identify four types of constraints:

    \begin{itemize}
        \item $t_i \prec t_j$ where $t_i,t_j \in U$: an \emph{ordering-constraint} meaning that in every valid \emph{solution} the last \emph{primitive task} (\emph{action}) in the \emph{solution} to which $t_i$ decomposes must precede the first \emph{primitive task} (\emph{action}) in the \emph{solution} to which $t_j$ decomposes,
        
        \item $before(l,U')$: \emph{before-constraint} symbolizing that in every valid \emph{solution} the literal $l$ must hold in a state right before the \emph{application} of a first \emph{action} to which $U' \subseteq U$ decomposes,
    
        \item $after(U',l)$: \emph{after-constraint} is similar to \emph{before-constraint} with the difference that the literal $l$ must hold in a state right after the last \emph{action} to which set $U'$ decomposes,
    
        \item $between(U',l,U'')$: \emph{between-constraint} is saying that the literal $l$ must hold in all states starting after the last \emph{action} of $U'$ and lasting until the state right before the \emph{application} of a first \emph{action} of $U''$.
    \end{itemize}

    We will say that the \emph{task network} is \emph{primitive} if and only if, all of the tasks are \emph{primitive}. A \emph{task network} having at least one \emph{compound task} will be called \emph{non-primitive}.
\end{defn}

\medskip\noindent
In accordance with the Definition~\ref{def01:5}, the more formal definition~\cite{complexity}~\cite{langclassification}~\cite{nau} of the \emph{task network} would contain some function $\alpha: U \rightarrow N$, which would map instances of \emph{primitive} and \emph{compound tasks} to the set of names of all \emph{tasks}. This function would allow us to have multiple instances of the same \emph{task} in the set of tasks $U$, each with a unique identifier. We will omit a function $\alpha$ because its context will always be clear.

\begin{defn}\label{def02:10}
    A \emph{method} is a triple $m = (compound(m),subtasks(m), \\ constraints(m))$, where $compound(m)$ is a \emph{compound  task} and $(subtasks(m), \\ constraints(m))$ is a \emph{task network}. $constraints(m)$ operate only with the tasks in $subtasks(m)$. Having a \emph{task network} $\omega=(U,C)$, \emph{compound task} $c \in U$, and an instance of \emph{method} $m$ from $M$. Then $m$ decomposes $c$ into $subtasks(m)$, creating a new \emph{task network} $\omega'=(U',C')$ of a form:

    \[
    \delta(\omega,c,m) = ((U-\{c\}) \cup subtasks(m), C' \cup constraints(m)),
    \]

    \noindent
    where $C'$ is a modification of $C$:

    \begin{itemize}
        \item replace each \emph{ordering-constraint} containing $c$ with new ones containing $subtasks(m)$, i.e., $\forall c' \in subtasks(m): c \prec x$ is replaced with $c' \prec x$ and $x \prec c$ is replaced with $x \prec c'$,
        
        \item replace each \emph{before-, after-, between-constraint} containing $c$ with new ones containing $subtasks(m)$. For example, we would replace \emph{before-constraint} $before(l,V)$ with $before(l,(V - \{c\}) \cup subtasks(m))$.
    \end{itemize}
\end{defn}

\medbreak\noindent
It is highly convenient to write planning \emph{methods} as a rewriting rules~\cite{ondrckova2023semantics}:

\[
T \rightarrow T_1,\dots,T_k \quad [C].
\]

\noindent
This rewriting rule symbolizing a \emph{method} is saying as follows: A \emph{method} which decomposes the \emph{compound task} $T$ into sub-tasks $T_1,\dots,T_k$ under the constraints $C$.

\medbreak\noindent
Definition~\ref{def02:10} works well for \emph{planning domains} without \emph{empty methods} (a \emph{method} that decomposes compound task into the empty set of subtasks). Using \emph{an empty method} creates undefined behavior because the decomposed compound task is removed from all constraints and thus it is unclear where the specified constraint should be checked. For this reason, we will later redefine \emph{method} decomposition. 

\begin{defn}\label{def02:11}
    A \emph{(HTN) planning domain} is a quadruple $\mathcal{D} = (\mathcal{L} \ / \ P, O, C, M$), where $\mathcal{L} \ / \ P$ and $O$ are first-order language (\emph{set of propositional symbols}) and a set of \emph{operators}, respectively, as described in the section \nameref{class_repre}, $C$ is a set of \emph{compound tasks} and $M$ represents a set of all \emph{methods}.

    \noindent
    \emph{Planning domain} will be referred to as \emph{totally-ordered} if all of the \emph{methods} in $M$ and the \emph{initial task network} are \emph{totally-ordered} (there is a total strict ordering of sub-tasks). \emph{Planning domains} that are not \emph{totally-ordered} will be referred to as \emph{partially-ordered}.
\end{defn}

\medskip\noindent
A first-order language $\mathcal{L}$ can be easily interchanged for a set of \emph{propositional symbols} $P$ due to the equivalent expressive power of \emph{set-theoretic representation} and \emph{classical representation}~\cite{nau}.

\begin{defn}\label{def02:12}
    A \emph{(hierarchical) planning problem} is a triple $\mathcal{P} = (s_0,\omega,\mathcal{D})$ that consists of \emph{initial state} of the world $s_0$, \emph{initial task network} $\omega$ and a \emph{planning domain} $\mathcal{D}$.
\end{defn}

\begin{defn}\label{def02:13}
    A \emph{solution} to the \emph{planning problem} $\mathcal{P}$ is a \emph{plan} $\pi=(a_1,\dots,a_k)$. This sequence of \emph{actions} is assembled from a \emph{primitive task network} $\omega'=(U', C')$ after the application of a sequence of \emph{methods} from $M$ to the \emph{initial task network} $\omega$. A \emph{solution} $\pi$ needs to be valid, i.e., $\gamma(s_0,\pi)$ is not undefined and also needs to satisfy all of the constraints in $C'$. That is:
    
    \begin{itemize}
        \item $t_i \prec t_j \implies i < j$,
        
        \item $before(l, V) \implies l \in s_{min\{i \; | \; a_i \; \in \; V\} \; - \; 1}$ (if the literal $l$ is negative then it must not be in a state, same applies for other constraints),
        
        \item $after(V,l) \implies l \in s_{max\{i \; | \; a_i \; \in \; V\}}$,
        
        \item $between(V',l,V'') \implies (\forall j, \; max\{i \; | \; a_i \; \in \; V'\} \; \leq \; j \; < \; min\{i \; | \; a_i \; \in \; V''\}: l \; \in \; s_j)$.
    \end{itemize}
    
    By $l$ we mean a ground instance of a literal $l$ (in the case of \emph{set-theoretic} representation it would be $p \in P$).
\end{defn}

\section{HTN and Context-free Grammars}

\medskip\noindent
With the knowledge acquired in the previous sections, we can try to map planning definitions and structures to the definitions and structures of the theory of Automata and Grammars. By doing so, we would be able to utilize already discovered knowledge and algorithms. Furthermore, it will allow us to prove different language classifications~\cite{langclassification}.

\medskip\noindent
The simplest example is to map \emph{classical planning problem} to the equivalent DFA, and vice versa. The mapped DFA generates all of the \emph{solutions}, i.e., \emph{plans} that are valid, \emph{applicable} to the \emph{initial state} $s_0$ and satisfy the goal $g$.

\begin{thm}\label{thm02:1}
    For every \emph{classical planning problem $\mathcal{P} = (S, A, \gamma, s_0, g)$}, where $(S, A, \gamma)$ is a \emph{planning domain}, there exists a DFA~\cite{chytil} $D = (Q, \Sigma, \delta, q_0, F)$ such that $D$ generates all the \emph{solutions} for $\mathcal{P}$.
\end{thm}
\begin{proof}
    The proof is straightforward. Having $\mathcal{P} = (S, A, \gamma, s_0, g)$, we can construct DFA $D = (S,A,\delta,s_0,S_g)$ where $S_g=\{s \in S | g \subseteq s\}$ and $\delta(s,a) = \gamma(s, a) = (s-\text{eff}^{\,\,-}(a)) \cup \text{eff}^{\,\,+}(a)$. We can easily see that every generated word (\emph{plan}) $\pi \in L(A)$ is also a valid \emph{solution} to the \emph{planning problem}. Every \emph{solution} is \emph{applicable} to the $q_0 = s_0$ because \emph{transition function} of $D$ imitates \emph{planning state-transition function} of $\mathcal{P}$. Every $\pi \in L(A)$ is a \emph{solution} because the set of accept states is $S_g$.
\end{proof}

\begin{thm}\label{thm02:2}
    For every DFA $D = (Q, \Sigma, \delta, q_0, F)$ there exists a correspondent \emph{classical planning problem $\mathcal{P} = (S, A, \gamma, s_0, g)$} where the set of \emph{solutions} of $\mathcal{P}$ is equal to $L(D)$.
\end{thm}
\begin{proof}
    Having DFA $D = (Q, \Sigma, \delta, q_0, F)$, we will construct \emph{planning problem} $\mathcal{P}$ with individual components defined as follows. Without loss of generality, we will rename states of $Q$. Each state $q \in Q$ will have a unique index $i$: $0 \leq i < |Q|$. $q_0$ is the \emph{initial state} of $D$. Now we define $\mathcal{P} = (S, A, \gamma, s_0, g)$ with:

    \begin{gather*}
        S = \{{\{i\} | q_i \in Q - F}\} \cup \{{\{i, goal\} | q_i \in F}\}, \\
        A = \{ \sigma = ( \{i\}, \{i, goal\}, \{j\} ) | \delta(q_i,\sigma) = q_j \; and \; q_j \notin F\} \cup \\ \{ \sigma = ( \{i\}, \{i\}, \{j, goal\} ) | \delta(q_i,\sigma) = q_j \; and \; q_j \in F\}, \\
        \gamma(s,a)=(s-\text{eff}^{\,\,-}(a)) \cup \text{eff}^{\,\,+}(a), \\
        s_0 = 
            \begin{cases}
                $\{0\}$, & \text{if $q_0 \notin F$},\\
                $\{0, goal\}$, & \text{if $q_0 \in F$},
            \end{cases} \\
        g = \{ goal \}.
    \end{gather*}

    Every generated word $\sigma_1\dots\sigma_n \in L(D)$ is correspondent to single \emph{solution} $\pi = (a_1, \dots, a_n)$. Each state of $\mathcal{P}$ is represented by an index (\emph{propositional symbol}) $i$ which specifies the state $q_i \in Q$. If a state is an accepting state, then the planning state $s$ has \emph{propositional symbol} $goal$. This is forced by the positive and negative effects of \emph{actions}.
\end{proof}

\begin{cor}\label{cor2:1}
    Classical planning is classified into the class of regular languages.
\end{cor}

\medskip\noindent
Now we will prove that \emph{totally-ordered} HTN planning can be represented as a context-free (CF) grammar and vice versa. These claims are extremely useful and will be used in the following parts of this thesis. Similar proofs are presented in~\cite{langclassification}.

\begin{thm}\label{thm02:3}
    For every CF grammar $G = (V_G, T_G, P_G, S_G)$~\cite{chytil} there exists a correspondent \emph{totally ordered planning problem} $\mathcal{P} = (s_0,\omega,\mathcal{D})$ with $\mathcal{D}=(P, O, C, M)$ such that the set of \emph{solutions} of $\mathcal{P}$ is equal to $L(G)$.
\end{thm}
\begin{proof}
    Constructing \emph{planning problem $\mathcal{P}$} is uncomplicated and intuitive because the structures are similar. All we need is to handle \emph{operators $o \in O$} so that the generated \emph{plans} are \emph{applicable} to the \emph{initial state} $s_0$. Having $G = (V_G,T_G,P_G,S_G)$ we construct $\mathcal{P} = (\{\}, (\{S_G\}, \{\}), \mathcal{D})$ with $\mathcal{D} = (\{\},T_G,V_G,M)$. \emph{Methods} are defined as follows:
    
    \[
    M = \{T \rightarrow T_1,\dots,T_k \; [ \; \{T_i \prec T_j \; | \; 1 \leq i < j \leq k\} \; ] \; | \; (T,T_1 \dots T_k) \in P_G\}.
    \]
    
    Using this construction, the \emph{planning problem $\mathcal{P}$} can now generate the set of \emph{plans} that equals $L(G)$. One problem is that the generated \emph{plans} might not be valid \emph{solutions}. This can be handled conveniently if we use empty sets for the preconditions of all \emph{operators}. Each $o \in O$ will be defined as $o = (\{\}, \{\}, \{\})$. The result of this modification is that every possible \emph{plan} is now a valid \emph{solution} if it can be decomposed from the \emph{initial task network}.
\end{proof}

\begin{thm}\label{thm02:4}
    For every \emph{totally ordered planning problem} $\mathcal{P} = (s_0,\omega,\mathcal{D})$ with $\mathcal{D}=(P, O, C, M)$ without \emph{before-, after-, between-constraints} there exists a CF language $L$ that is equal to the set of \emph{solutions} of $\mathcal{P}$.
\end{thm}
\begin{proof}
    Let $\mathcal{P} = (s_0,\omega = (U, C), \mathcal{D} = (P, O, C, M))$ be a \emph{totally ordered planning problem} in which constraints of each \emph{method} consist only of \emph{ordering-constraints}. We will construct CF grammar $G = (V_G, T_G, P_G, S_G)$ where $V_G = C, T_G = O$ and $S_G \in U$. We assume that the \emph{initial task network} $\omega$ consists of one task, $|U| = 1$. If there are more tasks (that are totally ordered by constraints $C$), we will add one extra production rule to the $P_G$ that rewrites the new starting symbol $S'_G$ to the given state of $\omega = (U, C)$. The set of production rules is defined as follows:
    
    \[
    P_G = \{(T, T_1\dots T_k) \; | \; (T, \{T_1, \dots, T_k\}, \{T_i \prec T_j \; | \; 1 \leq i < j \leq k\}) \in M\}.
    \]

    Grammar $G$ generates all \emph{plans} that can be generated with $\mathcal{P}$. Some of these \emph{plans} might be valid \emph{solutions} and some of them might not be \emph{applicable} to the \emph{initial state} $s_0$. In other words, $L(G)$ is a superset of all possible \emph{solutions} of $\mathcal{P}$. To solve this issue it is sufficient to use the fact that the intersection of a context-free language and a regular language is resulting into context-free language~\cite{chytil}. We can use Theorem~\ref{thm02:1} to build a DFA $D$ that will generate all \emph{plans} that are \emph{applicable} to $s_0$. The empty set of goal symbols $g = \emptyset$ will ensure that the language of $D$ equals to all possible \emph{plans} that are allowed by the planning \emph{operators} $O$. Having everything prepared, we can construct a CF language $L = L(G) \cap L(D)$ which is equal to the set of \emph{solutions} of $\mathcal{P}$.
\end{proof}

\begin{cor}\label{cor2:2}
Totally-ordered HTN planning is classified into the class of context-free languages.
\end{cor}

\section{HTN Plan Verification}

\medskip\noindent
Hierarchical plan verification can be seen as a reversal process to the decomposition of a \emph{initial task network} into a \emph{plan} that is \emph{applicable} to the \emph{initial state} $s_0$ and satisfies all constraints. Given a \emph{hierarchical planning domain} $\mathcal{D} = (P, O, C, M)$, \emph{initial task network} $\omega$, an \emph{initial state} $s_0$, and a \emph{plan} $\pi$, we ask if it is possible to decompose the $\omega$ into $\pi$ using $\mathcal{D}$. Depending on a hierarchical model or semantics specification, there might be some additional information and structures to the input of a plan verification problem. An approach for totally-ordered plan verification with \emph{method} preconditions is discussed here~\cite{cmyk}.       