\chapter{Hierarchical {P}lanning}

\medskip\noindent
Now that we have understood classical planning, we can move on to hierarchical planning or Hierarchical Task Network (HTN), to be precise. In HTN the goal alone is not to find an \emph{applicable plan} that will meet all of the criteria of the \emph{planning problem}. HTN focuses on accomplishing some set of tasks by decomposing them into sub-tasks with constraints like ordering and state conditions. A task is accomplished immediately upon all of his sub-tasks are accomplished. HTN is an extension of classical planning which gives us clues on how to find the proper \emph{plan}.

\medskip\noindent
As in classical planning, there are states of the world represented by the set of \emph{proposition symbols} or \emph{logical atoms} that are true in a state. We can \emph{apply actions} to states if the preconditions of \emph{actions} are satisfied (held in a state). These \emph{actions} will be called \emph{primitive tasks} in HTN. These tasks are executable right away and they change the current state to another one by applying negative and positive effects. In addition to \emph{primitive tasks} there are \emph{non-primitive tasks}. We will call them \emph{compound tasks}. These tasks cannot be executed and \emph{applied to a state}, rather they have to be decomposed into a set of sub-tasks (both \emph{primitive} and \emph{compound}) using decomposition \emph{methods}. Having an \emph{initial task network}, that is a set of tasks and a set of constraints, the goal is to decompose all tasks into \emph{primitive tasks} and find an ordering of these tasks so that the constraints are not violated. After doing so, it is important to check that the resulting \emph{plan} (a sequence of \emph{primitive tasks}) is a valid \emph{plan} and can be \emph{applied} to an \emph{initial state}.

\medskip\noindent
All of the following definitions are correspondent and equivalent to the definitions in the book \emph{Automated Planning: theory and practice (Chapter 11)}~\cite{nau} and other publications~\cite{langclassification}~\cite{cmyk}~\cite{ondrckova2023semantics}~\cite{ondrckova2024empty}.

\section{HTN Planning}

\begin{defn}\label{def02:9}
    A \emph{task network} is a pair $\omega = (U,C)$, where $U$ is a set of \emph{tasks} (primitive and compound) and $C$ is a set of constraints.
    
    For a \emph{solution} (\emph{plan}) to be valid we need to satisfy all of the constraints listed in $C$. We identify four types of constraints:

    \begin{itemize}
        \item $t_i \prec t_j$ where $t_i,t_j \in U$: an \emph{ordering-constraint} meaning that in every valid \emph{solution} the last \emph{primitive task} (\emph{action}) in the \emph{solution} to which $t_i$ decomposes must precede the first \emph{primitive task} (\emph{action}) in the \emph{solution} to which $t_j$ decomposes,
        
        \item $be\text{f}ore(l,U')$: \emph{before-constraint} symbolizing that in every valid \emph{solution} the literal $l$ must hold in a state right before the \emph{application} of a first \emph{action} to which $U' \subseteq U$ decomposes,
    
        \item $a\text{f}ter(U',l)$: \emph{after-constraint} is similar to \emph{before-constraint} with the difference that the literal $l$ must hold in a state right after the last \emph{action} to which set $U'$ decomposes,
    
        \item $between(U',l,U'')$: \emph{between-constraint} is saying that the literal $l$ must hold in all states starting after the last \emph{action} of $U'$ and lasting until the state right before the \emph{application} of a first \emph{action} of $U''$.
    \end{itemize}

    We will say that the \emph{task network} is \emph{primitive} if and only if, all of the tasks are \emph{primitive}. A \emph{task network} having at least one \emph{compound task} will be called \emph{non-primitive}.
\end{defn}

\medskip\noindent
The most used \emph{state-constraint} is \emph{a before-constraint} which can be modeled in various HTN planners. The usage and application of this constraint is obvious. Before the beginning of a task, we want to hold some preconditions that are significant for that particular task. For example, a user needs to input all of the information before he can continue with the paying; a player needs to complete all of the quests before he can move on to the next stage, or a warehouse robot needs to have permission set before he can execute some real-life tasks. Analogous \emph{after-constraint} has different use cases. We might use this constraint on the last task in \emph{the task network} to signalize our intentions which are not modeled with the tasks themselves. For example, we want to deallocate resources of the process after the completion, or we want to give a player new abilities after the completion of many tasks that might interleave. This constraint can be used as a shortcut in difficult models where the person responsible for the modeling cannot enumerate and decide the ordering of tasks perfectly. \emph{The between-constraint} represents an interval of states which hold some property. For example, we want a player to have a specific item in his inventory after the completion of one task and lasting until the other tasks, or an autonomous robot must hold a crate in all states meanwhile he moves from one location to another (possibly doing other unrelated things).

\medskip\noindent
In accordance with the Definition~\ref{def01:5}, the more formal definition~\cite{complexity}~\cite{langclassification}~\cite{nau} of the \emph{task network} would contain some function $\alpha: U \rightarrow N$, which would map instances of \emph{primitive} and \emph{compound tasks} to the set of names of all \emph{tasks}. This function would allow us to have multiple instances of the same \emph{task} in the set of tasks $U$, each with a unique identifier. We will omit a function $\alpha$ because its context will always be clear.

\begin{defn}\label{def02:10}
    A \emph{method} is a triple $m = (compound(m),subtasks(m), \\ constraints(m))$, where $compound(m)$ is a \emph{compound  task} and $(subtasks(m), \\ constraints(m))$ is a \emph{task network}. $constraints(m)$ operate only with the tasks in $subtasks(m)$. Having a \emph{task network} $\omega=(U,C)$, \emph{compound task} $c \in U$, and an instance of \emph{method} $m$ from $M$ such that $compound(m) = c$. Then $m$ decomposes $c$ into $subtasks(m)$, creating a new \emph{task network} $\omega'=(U',C')$ of a form:

    \[
    \delta(\omega,c,m) = ((U-\{c\}) \cup subtasks(m), C' \cup constraints(m)),
    \]

    \noindent
    where $C'$ is a modification of $C$:

    \begin{itemize}
        \item replace each \emph{ordering-constraint} containing $c$ with new ones containing $subtasks(m)$, i.e., $\forall c' \in subtasks(m): c \prec x$ is replaced with $c' \prec x$ and $x \prec c$ is replaced with $x \prec c'$,
        
        \item replace each \emph{before-, after-, between-constraint} containing $c$ with new ones containing $subtasks(m)$. For example, we would replace \emph{before-constraint} $be\text{f}ore(l,V)$ with $be\text{f}ore(l,(V - \{c\}) \cup subtasks(m))$.
    \end{itemize}
\end{defn}

\medbreak\noindent
It is highly convenient to write planning \emph{methods} as rewriting rules~\cite{ondrckova2023semantics}:

\[
T \rightarrow T_1,\dots,T_k \quad [C].
\]

\noindent
This rewriting rule symbolizing a \emph{method} is saying as follows: A \emph{method} which decomposes the \emph{compound task} $T$ into sub-tasks $T_1,\dots,T_k$ under the constraints $C$.

\medbreak\noindent
Definition~\ref{def02:10} works well for \emph{planning domains} without \emph{empty methods} (a \emph{method} that decomposes compound task into the empty set of subtasks). Using \emph{an empty method} creates undefined behavior because the decomposed compound task is removed from all constraints and thus it is unclear where the specified constraint should be checked. For this reason, we will later redefine \emph{method} decomposition. 

\begin{defn}\label{def02:11}
    A \emph{(HTN) planning domain} is a quadruple $\mathcal{D} = (\mathcal{L} \ / \ P, O, C, M$), where $\mathcal{L} \ / \ P$ and $O$ are first-order language (\emph{set of propositional symbols}) and a set of \emph{operators}, respectively, as described in the section \nameref{class_repre}, $C$ is a set of \emph{compound tasks} and $M$ represents a set of all \emph{methods}.

    \noindent
    \emph{Planning domain} will be referred to as \emph{totally-ordered} if all of the \emph{methods} in $M$ and the \emph{initial task network} are \emph{totally-ordered} (there is a total strict ordering of sub-tasks). \emph{Planning domains} that are not \emph{totally-ordered} will be referred to as \emph{partially-ordered}.
\end{defn}

\medskip\noindent
A first-order language $\mathcal{L}$ can be easily interchanged for a set of \emph{propositional symbols} $P$ due to the equivalent expressive power of \emph{set-theoretic representation} and \emph{classical representation}~\cite{nau}.

\begin{defn}\label{def02:12}
    A \emph{(hierarchical) planning problem} is a triple $\mathcal{P} = (s_0,\omega,\mathcal{D})$ that consists of \emph{initial state} of the world $s_0$, \emph{initial task network} $\omega$ and a \emph{planning domain} $\mathcal{D}$.
\end{defn}

\begin{defn}\label{def02:13}
    A \emph{solution} to the \emph{planning problem} $\mathcal{P}$ is a \emph{plan} $\pi=(a_1,\dots,a_k)$. This sequence of \emph{actions} is assembled from a \emph{primitive task network} $\omega'=(U', C'), \; U' = 
 \{a_i \; | \; 1 \leq i \leq k\}$, after the application of a sequence of \emph{methods} from $M$ to the \emph{initial task network} $\omega$. A \emph{solution} $\pi$ needs to be valid, i.e., $\gamma(s_0,\pi)$ is not undefined and also needs to satisfy all of the constraints in $C'$. That is:
    
    \begin{itemize}
        \item $a_i \prec a_j \implies i < j$,
        
        \item $be\text{f}ore(l, V) \implies l \in s_{min\{i \; | \; a_i \; \in \; V\} \; - \; 1}$ (if the literal $l$ is negative then it must not be in a state, same applies for other constraints),
        
        \item $a\text{f}ter(V,l) \implies l \in s_{max\{i \; | \; a_i \; \in \; V\}}$,
        
        \item $between(V',l,V'') \implies (\forall j, \; max\{i \; | \; a_i \; \in \; V'\} \; \leq \; j \; < \; min\{i \; | \; a_i \; \in \; V''\}: l \; \in \; s_j)$.
    \end{itemize}
    
    By $l$ we mean a ground instance of a literal $l$ (in the case of \emph{set-theoretic} representation it would be $p \in P$).
\end{defn}

\section{HTN and Context-free Grammars}

\medskip\noindent
With the knowledge acquired in the previous sections, we can try to map planning definitions and structures to the definitions and structures of the theory of Automata and Grammars. By doing so, we would be able to utilize already discovered knowledge and algorithms. Furthermore, it will allow us to prove different language classifications~\cite{langclassification}.

\medskip\noindent
The simplest example is to map \emph{classical planning problem} to the equivalent DFA, and vice versa. The mapped DFA generates all of the \emph{solutions}, i.e., \emph{plans} that are valid, \emph{applicable} to the \emph{initial state} $s_0$ and satisfy the goal $g$.

\begin{thm}\label{thm02:1}
    For every \emph{classical planning problem $\mathcal{P} = (S, A, \gamma, s_0, g)$}, where $(S, A, \gamma)$ is a \emph{planning domain}, there exists a DFA~\cite{chytil} $D = (Q, \Sigma, \delta, q_0, F)$ such that $D$ generates all the \emph{solutions} for $\mathcal{P}$.
\end{thm}
\begin{proof}
    The proof is straightforward. Having $\mathcal{P} = (S, A, \gamma, s_0, g)$, we can construct DFA $D = (S,A,\delta,s_0,S_g)$ where $S_g=\{s \in S | g \subseteq s\}$ and $\delta(s,a) = \gamma(s, a) = (s-\text{eff}^{\,\,-}(a)) \cup \text{eff}^{\,\,+}(a)$. We can easily see that every generated word (\emph{plan}) $\pi \in L(A)$ is also a valid \emph{solution} to the \emph{planning problem}. Every \emph{solution} is \emph{applicable} to the $q_0 = s_0$ because \emph{transition function} of $D$ imitates \emph{planning state-transition function} of $\mathcal{P}$. Every $\pi \in L(A)$ is a \emph{solution} because the set of accept states is $S_g$.
\end{proof}

\begin{thm}\label{thm02:2}
    For every DFA $D = (Q, \Sigma, \delta, q_0, F)$ there exists a correspondent \emph{classical planning problem $\mathcal{P} = (S, A, \gamma, s_0, g)$} where the set of \emph{solutions} of $\mathcal{P}$ is equal to $L(D)$.
\end{thm}
\begin{proof}
    Having DFA $D = (Q, \Sigma, \delta, q_0, F)$, we will construct \emph{planning problem} $\mathcal{P}$ with individual components defined as follows. Without loss of generality, we will rename states of $Q$. Each state $q \in Q$ will have a unique index $i$: $0 \leq i < |Q|$. $q_0$ is the \emph{initial state} of $D$. Now we define $\mathcal{P} = (S, A, \gamma, s_0, g)$ with:

    \begin{gather*}
        S = \{{\{i\} | q_i \in Q - F}\} \cup \{{\{i, goal\} | q_i \in F}\}, \\
        A = \{ \sigma = ( \{i\}, \{i, goal\}, \{j\} ) | \delta(q_i,\sigma) = q_j \; and \; q_j \notin F\} \cup \\ \{ \sigma = ( \{i\}, \{i\}, \{j, goal\} ) | \delta(q_i,\sigma) = q_j \; and \; q_j \in F\}, \\
        \gamma(s,a)=(s-\text{eff}^{\,\,-}(a)) \cup \text{eff}^{\,\,+}(a), \\
        s_0 = 
            \begin{cases}
                $\{0\}$, & \text{if $q_0 \notin F$},\\
                $\{0, goal\}$, & \text{if $q_0 \in F$},
            \end{cases} \\
        g = \{ goal \}.
    \end{gather*}

    Every generated word $\sigma_1\dots\sigma_n \in L(D)$ corresponds to a single \emph{solution} $\pi = (a_1, \dots, a_n)$. Each state of $\mathcal{P}$ is represented by an index (\emph{propositional symbol}) $i$ which specifies the state $q_i \in Q$. If a state is an accepting state, then the planning state $s$ has \emph{propositional symbol} $goal$. This is forced by the positive and negative effects of \emph{actions}.
\end{proof}

\begin{cor}\label{cor2:1}
    Classical planning is classified into the class of regular languages.
\end{cor}

\medskip\noindent
Now we will prove that \emph{totally-ordered} HTN planning can be represented as a context-free (CF) grammar and vice versa. These claims are extremely useful and will be used in the following parts of this thesis. Similar proofs are presented in~\cite{langclassification}.

\begin{thm}\label{thm02:3}
    For every CF grammar $G = (V_G, T_G, P_G, S_G)$~\cite{chytil} there exists a correspondent \emph{totally ordered planning problem} $\mathcal{P} = (s_0,\omega,\mathcal{D})$ with $\mathcal{D}=(P, O, C, M)$ such that the set of \emph{solutions} of $\mathcal{P}$ is equal to $L(G)$.
\end{thm}
\begin{proof}
    Constructing \emph{planning problem $\mathcal{P}$} is uncomplicated and intuitive because the structures are similar. All we need is to handle \emph{operators $o \in O$} so that the generated \emph{plans} are \emph{applicable} to the \emph{initial state} $s_0$. Having $G = (V_G,T_G,P_G,S_G)$ we construct $\mathcal{P} = (\{\}, (\{S_G\}, \{\}), \mathcal{D})$ with $\mathcal{D} = (\{\},T_G,V_G,M)$. \emph{Methods} are defined as follows:
    
    \[
    M = \{T \rightarrow T_1,\dots,T_k \; [ \; \{T_i \prec T_j \; | \; 1 \leq i < j \leq k\} \; ] \; | \; (T,T_1 \dots T_k) \in P_G\}.
    \]
    
    Using this construction, the \emph{planning problem $\mathcal{P}$} can now generate the set of \emph{plans} that equals $L(G)$. One problem is that the generated \emph{plans} might not be valid \emph{solutions}. This can be handled conveniently if we use empty sets for the preconditions of all \emph{operators}. Each $o \in O$ will be defined as $o = (\{\}, \{\}, \{\})$. The result of this modification is that every possible \emph{plan} is now a valid \emph{solution} if it can be decomposed from the \emph{initial task network}.
\end{proof}

\begin{thm}\label{thm02:4}
    For every \emph{totally ordered planning problem} $\mathcal{P} = (s_0,\omega,\mathcal{D})$ with $\mathcal{D}=(P, O, C, M)$ without \emph{before-, after-, between-constraints} there exists a CF language $L$ that is equal to the set of \emph{solutions} of $\mathcal{P}$.
\end{thm}
\begin{proof}
    Let $\mathcal{P} = (s_0,\omega = (U, C), \mathcal{D} = (P, O, C, M))$ be a \emph{totally ordered planning problem} in which constraints of each \emph{method} consist only of \emph{ordering-constraints}. We will construct CF grammar $G = (V_G, T_G, P_G, S_G)$ where $V_G = C, T_G = O$ and $S_G \in U$. We assume that the \emph{initial task network} $\omega$ consists of one task, $|U| = 1$. If there are more tasks (that are totally ordered by constraints $C$), we will add one extra production rule to the $P_G$ that rewrites the new starting symbol $S'_G$ to the given state of $\omega = (U, C)$. The set of production rules is defined as follows:
    
    \[
    P_G = \{(T, T_1\dots T_k) \; | \; (T, \{T_1, \dots, T_k\}, \{T_i \prec T_j \; | \; 1 \leq i < j \leq k\}) \in M\}.
    \]

    Grammar $G$ generates all \emph{plans} that can be generated with $\mathcal{P}$. Some of these \emph{plans} might be valid \emph{solutions} and some of them might not be \emph{applicable} to the \emph{initial state} $s_0$. In other words, $L(G)$ is a superset of all possible \emph{solutions} of $\mathcal{P}$. To solve this issue it is sufficient to use the fact that the intersection of a context-free language and a regular language is resulting into context-free language~\cite{chytil}. We can use Theorem~\ref{thm02:1} to build a DFA $D$ that will generate all \emph{plans} that are \emph{applicable} to $s_0$. The empty set of goal symbols $g = \emptyset$ will ensure that the language of $D$ equals to all possible \emph{plans} that are allowed by the planning \emph{operators} $O$. Having everything prepared, we can construct a CF language $L = L(G) \cap L(D)$ which is equal to the set of \emph{solutions} of $\mathcal{P}$.
\end{proof}

\begin{cor}\label{cor2:2}
Totally-ordered HTN planning without state-constraints is classified into the class of context-free languages.
\end{cor}

\section{HTN Plan Verification}

\medskip\noindent
Hierarchical plan verification can be seen as a reversal process to the decomposition of a \emph{initial task network} into a \emph{plan} that is \emph{applicable} to the \emph{initial state} $s_0$ and satisfies all constraints. Given a \emph{hierarchical planning domain} $\mathcal{D} = (P, O, C, M)$, \emph{initial task network} $\omega$, an \emph{initial state} $s_0$, and a \emph{plan} $\pi$, we ask if it is possible to decompose the $\omega$ into $\pi$ using $\mathcal{D}$. Depending on a hierarchical model or semantics specification, there might be some additional information and structures to the input of a plan verification problem. For example, we might analyse totally-ordered plan verification with \emph{method} preconditions~\cite{cmyk}.

\section{{HTN} Semantics with Goal Tasks}

\medskip\noindent
Up to now, we have only discussed HTN definitions based on the book \emph{Automated Planning: theory and practice}~\cite{nau}. This book does not consider \emph{goal tasks}~\cite{complexity} which are very similar to the \emph{goals} in classical planning (Definition~\ref{def01:2}). \emph{Goal tasks} are attached to the \emph{compound tasks} and define the set of \emph{propositional symbols} (or logical atoms) that need to hold in a state after the execution of all \emph{primitive tasks} to which \emph{the compound task} decomposes. In the case of \emph{primitive task}, the set of positive effects is logically equivalent to the \emph{goal task} of that task. 

\medskip\noindent
Many formalisms for describing hierarchical planning exist, and each of them comes with different approaches to define and propose \emph{hierarchical planning problems}. Each formalism allows diverse features that might come in handy during modeling or planning of the \emph{planning problems}. For example, HDDL~\cite{hddl}, allows to specify \emph{goal state} which is equivalent to the set of \emph{goal predicate symbols} defined in Definition~\ref{def01:2}. For a \emph{plan} to be valid in HDDL, a sequence of \emph{task decompositions} transforming \emph{the initial task network} into \emph{the primitive task network} must exist. Also, \emph{the primitive task network} must satisfy all constraints, a linear ordering of \emph{primitive tasks (actions)} must exist, and the state after the execution of the \emph{plan} must hold \emph{propositional symbols} defined in \emph{goal state}. This is a great feature but the definition of \emph{a goal state} is allowed only for the whole \emph{planning problem} and not for the individual tasks. On the other hand, alternative formalism~\cite{complexity} grant the feature of \emph{goal tasks} which is noticeably more flexible than HDDL's formalism.

\medskip\noindent
Now we will present a way of using \emph{goal tasks} in modeling and planning. The idea is to omit the negative effects of \emph{actions}. This way, all \emph{actions} will only append \emph{predicate symbols} to the state (which is defined as an element of the set $2^P$). In such a manner, the planning might remind us of monotone functions. The sequence of intermediate states $(s_0, \dots, s_k)$, created by the \emph{plan} $\pi = (a_1, \dots, a_k)$, has a non-decreasing size of \emph{propositional symbols} in a state. Thus, we can call this subclass of \emph{planning problems} – \emph{monotone hierarchical planning}.

\medskip\noindent
With the knowledge from the previous paragraph, let's combine the concepts of \emph{goal tasks}, \emph{monotone hierarchical planning}, and totally-ordered \emph{planning domains}. Assume a \emph{compound task} $T$ is decomposed into the subtasks $T_1, \dots, T_k$ (with the ordering  $T_1 \prec \dots \prec T_k$) with given \emph{goal tasks}. Because of the totally-ordered domain and the \emph{monotone hierarchical planning}, we can use the technique divide and conquer and try to find the decompositions of subtasks independently. Furthermore, the subtask $T_i$ might take into consideration \emph{propositional symbols} contained in \emph{goal tasks} of subtasks $T_1, \dots, T_{i - 1}$. These symbols can be viewed as granted because of the fact that there are no negative effects and all methods are totally-ordered.